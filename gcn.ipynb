{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gcn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giuseppefutia/machine-learning/blob/master/gcn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ddeqCjBdplSj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# A Learning Guide to Graph Convolutional Networks\n",
        "\n",
        "* Describe the concept of Deep Learning on Graphs.\n",
        "* Describe the 3 types of Graph Deep Learning methods.\n",
        "* Describe in which category resides the Graph Convolutional Networks among the previous ones.\n",
        "\n",
        "Sources: \n",
        "* A Beginner's Guide to Graph Analytics and Deep Learning: https://skymind.ai/wiki/graph-analysis\n",
        "* https://arxiv.org/abs/1812.04202\n",
        "\n",
        "## Graph Data Features and Issues\n",
        "\n",
        "* Irregular domain.\n",
        "    \n",
        "* Diverse structures and tasks.\n",
        "\n",
        "* Scalability and parallelization.\n",
        "  \n",
        "* Interdiscipline.\n",
        "\n",
        "Sources: \n",
        " * Source: Youtube: https://www.youtube.com/watch?v=4pasBJ_hPMQ.\n",
        "    * Introduce the concept of non-euclidean data.\n",
        "         * https://arxiv.org/pdf/1611.08097.pdf\n",
        "         * https://www.youtube.com/watch?v=b187J4ndZWY\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "KNTxLtEGBFBD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Notation and Representation\n",
        "In this section we provide some notation in order to describe a graph and we describe how we can represent graphs using matrices.\n",
        "\n",
        "### Graph Notation\n",
        "TODO\n",
        "\n",
        "### How to Represent Graph Using Matrices\n",
        "Machine learning algorithms are able to process data in the form of matrices. For such reasons, we need to understand how we can represent graph using matrices.\n",
        "\n",
        "Consider the following graph example:\n",
        "\n",
        "![Graph example](http://graphonline.ru/tmp/saved/RF/RFAOxGXmjawkuiWO.png =300x)\n",
        "\n",
        "We can represent this graph using the following matrices.\n",
        "\n",
        "#### Incidence Matrix\n",
        "An incidence matrix is a matrix that shows the relationship between two classes of objects (nodes and objects). Incidence matrices can describe directed and undirected graphs.\n",
        "\n",
        "In case of an undirected graph (like our example), we adopt an unoriented incidecence matrix is a $n × m$ matrix $B$, where $n$ and $m$ are the numbers of vertices and edges respectively, such that $B_{i,j} = 1$ if the vertex $v_i$ and edge $e_j$ are incident and 0 otherwise.\n",
        "\n",
        "The incidence matrix of our graph example is the following:\n",
        "\n",
        "$\\begin{bmatrix}\n",
        "  1. & 1. & 1. & 0 \\\\\n",
        "  1. & 0. & 0. & 0 \\\\\n",
        "  0. & 0. & 1. & 1 \\\\\n",
        "  0. & 1. & 0. & 1 \\\\\n",
        "\\end{bmatrix}$\n",
        "\n",
        "#### Adjacency Matrix\n",
        "\n",
        "An adjacency matrix is a square matrix used to represent a finite graph. The elements of the matrix indicate whether pairs of vertices are adjacent or not in the graph. \n",
        "\n",
        "If the graph is undirected, the adjacency matrix is symmetric. The adjacency matrix of our graph example is the following:\n",
        "\n",
        "$\\begin{bmatrix}\n",
        "  0. & 1. & 1. & 1 \\\\ \n",
        "  1. & 0. & 0. & 0 \\\\ \n",
        "  1. & 0. & 0. & 1 \\\\ \n",
        "  1. & 0. & 1. & 0 \\\\ \n",
        "\\end{bmatrix}$\n",
        "\n",
        "#### Degree Matrix\n",
        "The degree matrix is a diagonal matrix which contains information about the degree of each vertex—that is, the number of edges attached to each vertex.\n",
        "\n",
        "The degree is used together with the adjacency matrix to construct the Laplacian matrix of a graph (that we explore in the following section). The degree matrix of our graph example is the following: \n",
        "\n",
        "$\\begin{bmatrix}\n",
        "  3. & 0. & 0. & 0 \\\\ \n",
        "  0. & 1. & 0. & 0 \\\\ \n",
        "  0. & 0. & 2. & 0 \\\\ \n",
        "  0. & 0. & 0. & 2 \\\\ \n",
        "\\end{bmatrix}$\n",
        "\n",
        "#### Laplacian Matrix\n",
        "The Laplacian matrix, sometimes called admittance matrix, Kirchhoff matrix or discrete Laplacian, is a matrix representation of a graph. It can be used to calculate the number of spanning trees for a given graph and to to construct low dimensional embeddings, which can be useful for a variety of machine learning applications.\n",
        "\n",
        "Given a simple graph $G$ with $n$ vertices, its Laplacian matrix ${\\textstyle L_{n\\times n}} $ is defined as:\n",
        "\n",
        "${\\displaystyle L=D-A,}$ where $D$ is the degree matrix and $A$ is the adjacency matrix of the graph.\n",
        "\n",
        "Let's see the representation of the Laplacian matrix using numpy: \n"
      ]
    },
    {
      "metadata": {
        "id": "1mgpfnSQBZlx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "3d1c5b0b-b44d-4be7-a4bb-eb59a1fee171"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Adjacency Matrix - Size (4,4)\n",
        "A = np.matrix([\n",
        "    [0, 1, 1, 1],\n",
        "    [1, 0, 0, 0], \n",
        "    [1, 0, 0, 1],\n",
        "    [1, 0, 1, 0]],\n",
        "    dtype=float\n",
        ")\n",
        "print()\n",
        "print()\n",
        "print('Adjacency Matrix')\n",
        "print(A)\n",
        "\n",
        "# Degree Matrix - Size (4,4)\n",
        "D = np.matrix([\n",
        "    [3, 0, 0, 0],\n",
        "    [0, 1, 0, 0],\n",
        "    [0, 0, 2, 0],\n",
        "    [0, 0, 0, 2]],\n",
        "    dtype=float\n",
        ")\n",
        "\n",
        "print()\n",
        "print()\n",
        "print('Degree Matrix')\n",
        "print(D)\n",
        "\n",
        "# The Degree Matrix can be computed from the Adjacency Matrix\n",
        "D_from_A = np.array(np.sum(A, axis=0))[0]\n",
        "D_from_A = np.matrix(np.diag(D_from_A))\n",
        "\n",
        "print()\n",
        "print()\n",
        "print('Computed Degree Matrix from Adjacency one')\n",
        "print(D_from_A)\n",
        "\n",
        "\n",
        "# Laplacian matrix - Size (4,4)\n",
        "L = D-A\n",
        "\n",
        "print()\n",
        "print()\n",
        "print('Laplacian Matrix')\n",
        "print(L)\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Adjacency Matrix\n",
            "[[0. 1. 1. 1.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 1.]\n",
            " [1. 0. 1. 0.]]\n",
            "\n",
            "\n",
            "Degree Matrix\n",
            "[[3. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 2. 0.]\n",
            " [0. 0. 0. 2.]]\n",
            "\n",
            "\n",
            "Computed Degree Matrix from Adjacency one\n",
            "[[3. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 2. 0.]\n",
            " [0. 0. 0. 2.]]\n",
            "\n",
            "\n",
            "Laplacian Matrix\n",
            "[[ 3. -1. -1. -1.]\n",
            " [-1.  1.  0.  0.]\n",
            " [-1.  0.  2. -1.]\n",
            " [-1.  0. -1.  2.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ox1-MhTHYk5J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Through the observation of the laplacian matrix of a simple graph (no loop edges for each node), we can notice the following features:\n",
        "\n",
        "* if $i=j$, the value of the cell is equal to $deg(v_i)$\n",
        "* if $i \\neq j$, and $v_i$ is adjacent to $v_j$, the value is equal to $-1$\n",
        "* otherwise, $0$\n",
        "\n",
        "We can also obtain the **symmetric normalized laplacian matrix**, that is defined as follows:\n",
        "\n",
        "$L^{sym} := D^{-1/2}LD^{-1/2}=I-D^{-1/2}AD^{-1/2}$\n",
        "\n",
        "Let's compute the symmetric normalized laplacian using numpy:"
      ]
    },
    {
      "metadata": {
        "id": "VMh75j87fMZU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "665ef4a3-15a8-4f7d-9d36-e9e410fce30d"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Adjacency Matrix - Size (4,4)\n",
        "A = np.matrix([\n",
        "    [0, 1, 1, 1],\n",
        "    [1, 0, 0, 0], \n",
        "    [1, 0, 0, 1],\n",
        "    [1, 0, 1, 0]],\n",
        "    dtype=float\n",
        ")\n",
        "\n",
        "print()\n",
        "print()\n",
        "print('Adjacency Matrix')\n",
        "print(A)\n",
        "\n",
        "# The Degree Matrix can be computed from the Adjacency Matrix\n",
        "D_from_A = np.array(np.sum(A, axis=0))[0]\n",
        "D_from_A = np.matrix(np.diag(D_from_A))\n",
        "\n",
        "print()\n",
        "print()\n",
        "print('Computed Degree Matrix from Adjacency one')\n",
        "print(D_from_A)\n",
        "\n",
        "# Laplacian matrix - Size (4,4)\n",
        "L = D_from_A-A\n",
        "\n",
        "print()\n",
        "print()\n",
        "print('Laplacian Matrix')\n",
        "print(L)\n",
        "\n",
        "# Inverse Degree Matrix\n",
        "D_hat = np.sqrt(D_from_A)\n",
        "\n",
        "L_sym_1 = D_hat * L * D_hat\n",
        "\n",
        "print()\n",
        "print()\n",
        "print('L_sym_1')\n",
        "print(L_sym_1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Adjacency Matrix\n",
            "[[0. 1. 1. 1.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 1.]\n",
            " [1. 0. 1. 0.]]\n",
            "\n",
            "\n",
            "Computed Degree Matrix from Adjacency one\n",
            "[[3. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 2. 0.]\n",
            " [0. 0. 0. 2.]]\n",
            "\n",
            "\n",
            "Laplacian Matrix\n",
            "[[ 3. -1. -1. -1.]\n",
            " [-1.  1.  0.  0.]\n",
            " [-1.  0.  2. -1.]\n",
            " [-1.  0. -1.  2.]]\n",
            "\n",
            "\n",
            "L_sym_1\n",
            "[[ 9.         -1.73205081 -2.44948974 -2.44948974]\n",
            " [-1.73205081  1.          0.          0.        ]\n",
            " [-2.44948974  0.          4.         -2.        ]\n",
            " [-2.44948974  0.         -2.          4.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zkufmcZgbJSK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TODO: Understanding normalized Laplacian Matrix:\n",
        "\n",
        "* https://www.youtube.com/playlist?list=PLkpN8cIB_rZFgZK6WLZu7n88c6cjgE2Kw\n",
        "\n",
        "* https://math.stackexchange.com/questions/1113467/why-laplacian-matrix-need-normalization-and-how-come-the-sqrt-of-degree-matrix\n",
        "\n",
        "* http://www.cs.yale.edu/homes/spielman/PAPERS/SGTChapter.pdf\n",
        "\n",
        "* https://people.orie.cornell.edu/dpw/orie6334/lecture7.pdf\n",
        "\n",
        "* https://people.orie.cornell.edu/mru8/orie4741/lectures/spectral.pdf\n",
        "\n",
        "* https://people.orie.cornell.edu/dpw/orie6334/index.html\n",
        "\n",
        "* https://blog.xrds.acm.org/2014/05/the-geometric-origins-of-spectral-graph-theory/\n",
        "\n",
        "* https://lucatrevisan.wordpress.com/2016/02/01/cs294-lecture-2-basics-of-spectral-graph-theory/"
      ]
    },
    {
      "metadata": {
        "id": "OpabWzVyBTtC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Deepening on GCN\n",
        "\n",
        "Sources: \n",
        "* https://www.youtube.com/playlist?list=PLLyXKRG8-SS0cggcM_xWby7HQHOnECVuD"
      ]
    },
    {
      "metadata": {
        "id": "ix0ZCnLF1iTt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Numpy Implementation - Forward Propagation\n",
        "Sources: https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780"
      ]
    },
    {
      "metadata": {
        "id": "-5otxIoa1C2e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Adjacency Matrix - Size (4,4).\n",
        "A = np.matrix([\n",
        "    [0, 1, 0, 0],\n",
        "    [0, 0, 1, 1], \n",
        "    [0, 1, 0, 0],\n",
        "    [1, 0, 1, 0]],\n",
        "    dtype=float\n",
        ")\n",
        "print('Adjacency Matrix')\n",
        "print(A)\n",
        "print()\n",
        "\n",
        "# Feature Matrix - Size (4.2).\n",
        "X = np.matrix([\n",
        "            [i, -i]\n",
        "            for i in range(A.shape[0])\n",
        "        ], dtype=float)\n",
        "\n",
        "print('Feature Matrix')\n",
        "print(X)\n",
        "print()\n",
        "\n",
        "# Applying the propagation rule to obtain an embedding representation of nodes\n",
        "# from the adjacency matrix. With the following operation, we represent each\n",
        "# node of the graph with two elements (because of the dimension of the feature matrix).\n",
        "L1 = A * X\n",
        "print ('Forward rule')\n",
        "print(L1)\n",
        "print()\n",
        "\n",
        "# Note: The representation of each node (each row) is now a sum of its neighbors\n",
        "# features. In other words, the graph convolutional layer represents each node \n",
        "# as an aggregate of its neighborhood.\n",
        "\n",
        "# The aggregated representation of a node does not include its own features, for\n",
        "# these reasons we need to include a self-loop. To compute this self-loop, we\n",
        "# need to add an identity matrix to the adjacency matrix before applying the\n",
        "# propagation rules.\n",
        "I = np.matrix(np.eye(A.shape[0]))\n",
        "A_hat = A + I\n",
        "L1 = A_hat * W1\n",
        "print ('Forward rule with the first loop')\n",
        "print(L1)\n",
        "print()\n",
        "\n",
        "# To avoid vanishing and explosion gradients issues, we need to normalize the\n",
        "# feature representation of data. We can perform this normalization multiplying\n",
        "# the adjancecy matrix with the inverse degree matrix. The degree matrix is\n",
        "# computed summing the values in each adjacency matrix row and then put this\n",
        "# values in a diagonal matrix\n",
        "\n",
        "D = np.array(np.sum(A, axis=0))[0]\n",
        "print('Degree Matrix starting from the Adjacency Matrix')\n",
        "print(D)\n",
        "print()\n",
        "D = np.matrix(np.diag(D))\n",
        "print('Inverse of Degree Matrix starting from the Adjacency Matrix')\n",
        "print(D**-1)\n",
        "print()\n",
        "\n",
        "# In order to train the network, we need to define a matrix weight\n",
        "W = np.matrix([\n",
        "    [1, -1],\n",
        "    [-1, 1]\n",
        "])\n",
        "print('Weight Matrix')\n",
        "print(W)\n",
        "print()\n",
        "\n",
        "# Before comple the propagation we need to create the degree matrix from A_hat\n",
        "# and not simply A. After that you need to compute the entire propagation\n",
        "D_hat = np.array(np.sum(A_hat, axis=0))[0]\n",
        "D_hat = np.matrix(np.diag(D_hat))\n",
        "forward = D_hat**-1 * A_hat * X * W\n",
        "print('Forward computation')\n",
        "print(forward)\n",
        "print()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KyndfiRf2DzF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Forward Propagation Using Real Data\n",
        "Source: https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780 "
      ]
    },
    {
      "metadata": {
        "id": "447DRiyn2Kr_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bYhyPHgY2LmB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Pytorch Implementation - Semi-Supervised Learning with Spectral Graph Convolutions\n",
        "Source: https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-62acf5b143d0"
      ]
    },
    {
      "metadata": {
        "id": "X97pQDVMI7yr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}