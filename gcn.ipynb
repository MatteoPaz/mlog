{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gcn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giuseppefutia/machine-learning/blob/master/gcn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ddeqCjBdplSj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# A Learning Guide for Graph Convolutional Networks\n",
        "\n",
        "* Describe the concept of Deep Learning on Graphs.\n",
        "* Describe the 3 types of Graph Deep Learning methods.\n",
        "* Describe in which category resides the Graph Convolutional Networks among the previous ones.\n",
        "\n",
        "Sources: https://arxiv.org/abs/1812.04202.\n",
        "\n",
        "## Graph Data Features and Issues\n",
        "\n",
        "* Graph Features:\n",
        "    * Source: Youtube: https://www.youtube.com/watch?v=4pasBJ_hPMQ.\n",
        "\n",
        "* Irregular domain.\n",
        "    * Introduce the concept of non-euclidean data.\n",
        "    * Sources: https://arxiv.org/pdf/1611.08097.pdf, https://www.youtube.com/watch?v=b187J4ndZWY\n",
        "    \n",
        "* Diverse structures and tasks.\n",
        "\n",
        "* Scalability and parallelization.\n",
        "\n",
        "* Interdiscipline.\n",
        "\n",
        "\n",
        "## Notation\n",
        "\n",
        "* Graphs notation: which are the main features of a graph? \n",
        "\n",
        "* Graphs Matrix-related: how to describe matrices using graph?\n",
        "    * Sources: https://www.youtube.com/playlist?list=PLwGGHdZQPnBQBLF0F5ixBbSyv3DkINw0t.\n",
        "    * Scource, Wikipedia: https://en.wikipedia.org/wiki/Graph_theory#Graph-theoretic_data_structures.\n",
        "\n",
        "## Deepening on GCN\n",
        "Sources: https://www.youtube.com/playlist?list=PLLyXKRG8-SS0cggcM_xWby7HQHOnECVuD\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ix0ZCnLF1iTt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Numpy Implementation - Forward Propagation\n",
        "Sources: https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780"
      ]
    },
    {
      "metadata": {
        "id": "-5otxIoa1C2e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Adjacency Matrix - Size (4,4).\n",
        "A = np.matrix([\n",
        "    [0, 1, 0, 0],\n",
        "    [0, 0, 1, 1], \n",
        "    [0, 1, 0, 0],\n",
        "    [1, 0, 1, 0]],\n",
        "    dtype=float\n",
        ")\n",
        "print('Adjacency Matrix')\n",
        "print(A)\n",
        "print()\n",
        "\n",
        "# Feature Matrix - Size (4.2).\n",
        "X = np.matrix([\n",
        "            [i, -i]\n",
        "            for i in range(A.shape[0])\n",
        "        ], dtype=float)\n",
        "\n",
        "print('Feature Matrix')\n",
        "print(X)\n",
        "print()\n",
        "\n",
        "# Applying the propagation rule to obtain an embedding representation of nodes\n",
        "# from the adjacency matrix. With the following operation, we represent each\n",
        "# node of the graph with two elements (because of the dimension of the feature matrix).\n",
        "L1 = A * X\n",
        "print ('Forward rule')\n",
        "print(L1)\n",
        "print()\n",
        "\n",
        "# Note: The representation of each node (each row) is now a sum of its neighbors\n",
        "# features. In other words, the graph convolutional layer represents each node \n",
        "# as an aggregate of its neighborhood.\n",
        "\n",
        "# The aggregated representation of a node does not include its own features, for\n",
        "# these reasons we need to include a self-loop. To compute this self-loop, we\n",
        "# need to add an identity matrix to the adjacency matrix before applying the\n",
        "# propagation rules.\n",
        "I = np.matrix(np.eye(A.shape[0]))\n",
        "A_hat = A + I\n",
        "L1 = A_hat * W1\n",
        "print ('Forward rule with the first loop')\n",
        "print(L1)\n",
        "print()\n",
        "\n",
        "# To avoid vanishing and explosion gradients issues, we need to normalize the\n",
        "# feature representation of data. We can perform this normalization multiplying\n",
        "# the adjancecy matrix with the inverse degree matrix. The degree matrix is\n",
        "# computed summing the values in each adjacency matrix row and then put this\n",
        "# values in a diagonal matrix\n",
        "\n",
        "D = np.array(np.sum(A, axis=0))[0]\n",
        "print('Degree Matrix starting from the Adjacency Matrix')\n",
        "print(D)\n",
        "print()\n",
        "D = np.matrix(np.diag(D))\n",
        "print('Inverse of Degree Matrix starting from the Adjacency Matrix')\n",
        "print(D**-1)\n",
        "print()\n",
        "\n",
        "# In order to train the network, we need to define a matrix weight\n",
        "W = np.matrix([\n",
        "    [1, -1],\n",
        "    [-1, 1]\n",
        "])\n",
        "print('Weight Matrix')\n",
        "print(W)\n",
        "print()\n",
        "\n",
        "# Before comple the propagation we need to create the degree matrix from A_hat\n",
        "# and not simply A. After that you need to compute the entire propagation\n",
        "D_hat = np.array(np.sum(A_hat, axis=0))[0]\n",
        "D_hat = np.matrix(np.diag(D_hat))\n",
        "forward = D_hat**-1 * A_hat * X * W\n",
        "print('Forward computation')\n",
        "print(forward)\n",
        "print()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KyndfiRf2DzF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Forward Propagation Using Real Data\n",
        "Source: https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780 "
      ]
    },
    {
      "metadata": {
        "id": "447DRiyn2Kr_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bYhyPHgY2LmB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Pytorch Implementation - Semi-Supervised Learning with Spectral Graph Convolutions\n",
        "Source: https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-62acf5b143d0"
      ]
    },
    {
      "metadata": {
        "id": "X97pQDVMI7yr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}